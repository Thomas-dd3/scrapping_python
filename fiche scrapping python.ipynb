{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do web requests in python, use \"requests\" library\n",
    "# https://requests.readthedocs.io/en/master/user/quickstart/#make-a-request\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the request\n",
    "url = \n",
    "headers = {'User-Agent': '', 'Accept': '', }\n",
    "cookies = dict(key='value')\n",
    "\n",
    "# Making the request\n",
    "r = requests.get(url, headers=headers, cookies=cookies)\n",
    "\n",
    "# Ckecking the request\n",
    "if r.status_code != 200:\n",
    "    print('Error webpage status code : ' + r.status_code)\n",
    "    r.raise_for_status()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the result\n",
    "r.text\n",
    "\n",
    "# Get the cookies\n",
    "r.cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with request in loop, it is a good idea to add a sleep in order to reduce the risk to get ban.\n",
    "import time\n",
    "import random\n",
    "\n",
    "TIME_MIN_RANDOM_SEC = 2\n",
    "TIME_MAX_RANDOM_SEC = 6\n",
    "\n",
    "time.sleep(random.randint(TIME_MIN_RANDOM_SEC,TIME_MAX_RANDOM_SEC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To navigate in the dom and get the needed info, use \"BeautifulSoup\" library\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html5lib')\n",
    "# or just soup = BeautifulSoup(r.text)\n",
    "# there is other parser, look at the documentation if needed - 'html.paser', 'lxml', 'html5lib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a prettify version of the webpage\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be used as followed\n",
    "soup.title\n",
    "soup.body\n",
    "soup.a\n",
    "\n",
    "soup.h1.parent\n",
    "\n",
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a csv through a datagrame, use \"pandas\" library\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame\n",
    "df = pd.DataFrame(data=data, index=, columns=['a','b','c',...],..)\n",
    "# add line\n",
    "df = df.append({'a': 'test', 'b': 'coucou', 'c': 'salut'}, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
